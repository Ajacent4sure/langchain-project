{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"../data/LLM_Answers.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='1 \\n \\nLLM ASSIGNMENT SOLUTIONS \\n \\n1. LLMs is an alias for Large Language Models which are deep learning models that are \\nbased on neural networks with very huge parameters. These models learn from \\ntrillions of datasets to understand patterns in human languag es: the contexts, \\ngrammar, semantics and every other elements of human languages. \\n \\n2. LLMs are based on what is called Transformer architecture, and this enables the \\nsequential procession of text efficiently by understanding the interrelatedness of \\nwords in sent ences, paragraphs, and larger amounts of words. This  allows these \\nmodels to have the capability to perform many natural language processing such as \\nsummarisation and translation. \\nThey rely on transfer learning, this means that they can transfer whatever th ey have \\nlearned during their training with a very huge dataset to slimmer and more focused \\ntext-related tasks. \\n \\n3. Customer service, content generation, and chatbots derive great benefits from Large \\nLanguage Models (LLMs) because they provide natural, context ual, and efficient \\ninteractions. In customer service , for instance, they improve response speed and \\naccuracy, and they can proffer solutions without human engagement, and this can be \\ndone any time of the day. Also, in content generation, LLMs can create high-quality, \\ncreative, and coherent text, that will take a lot of hours for humans to generate. LLMs \\nalso improve chatbots by engaging in more human-like conversations, understanding \\ncomplex queries, and adapting to diverse contexts.  \\n \\n4. Common challenges include: \\n '),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='2 \\n \\ni. Biases in Outputs: LLMs often represent biases embedded in the training data, \\nleading to the generation of outputs that reflect stereotypes, discriminatory \\npatterns, or harmful content. When the data upon which an LLM is trained is \\nimbalanced, and has some socio-cultural or socio-political patterns, it will be \\ninevitable for the models to reinforc e these imbalances. An example of this is \\nthe varying opinions and dispositions of people towards LGBTQ as its legality \\nis not universal and contradicts some religious doctrines. \\nii. High Computational Cost: Training and deploying LLMs require substantial \\ncomputational resources, including high -performance GPUs or TPUs and \\nsignificant amounts of electricity. \\niii. Data Privacy Concern: LLMs trained on large datase ts will inadvertently \\nrephrase and reproduce sensitive information which can put human lives at risk \\nand jeopardise security. \\niv. Hallucination and Misinformation: LLMs sometimes generate content that is \\nincorrect and sound fabricated. This can lead to misinformation, and reliance on \\nsuch information can wreak havoc. An example of this is medical content that \\nmay not be based on scientific authorization. Also, the misuse of LLMs can lead \\nto harmful applications such as generating deepfake  content, spreading \\ndisinformation, or automating harmful behaviour.  \\nv. Availablity: The large size and resource demand of LLMs make deployment on \\nedge devices challenging, limiting the accessibility by many users. \\n5. Fine-tuning: This is the process of adapting a pre-trained neural network which has \\nbeen trained on a huge data to now  perform a new, specific, or streamlined task. It \\nfocuses on performing a specialized task rather than a wide-scope task. \\nFine-tuning can be applied in various fields, for instance, it can help with customer \\nservice by enabling the LLMs model to understand and resolve customer queries, \\nand proffer solutions. It can also be used in creative writing by fine-tuning human-\\nwritten scripts to meet a specific standard or style of writing. \\n '),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='3 \\n \\n6. The training phase of an LLM involves teaching the model to understand language \\npatterns by processing huge datasets and adjusting internal paramete rs (weights) \\nthrough iterative forward and backward passes to minimize prediction errors. This \\nphase is resource-intensive, requiring significant computational power and time. On \\nthe other hand, the inference phase applies the already trained model to real -world \\ntasks by performing a single forward pass to generate outputs like text completions \\nor answers. Training occurs infrequently and focuses on learning, while inference \\nhappens repeatedly during application. \\n \\n7. Large Language Models manage long inputs or  multiple paragraphs of text by \\nbreaking them into smaller units, like words. Transformers then use mechanisms \\nlike self-attention to understand relationships between these words, even when they \\nappear far apart in the sequence. This ensures LLMs maintain coherence while \\nhandling large inputs effectively. \\n \\n8. Large Language Models might perform badly in a situation where there is \\nambiguous or poorly framed prompts, where the model might misinterpret user \\nintent or generate irrelevant or nonsensical outputs due to the lack of clear context. \\nAnother scenario where LLMs might perform poorly is in a situation whereby \\nprecise factual accuracy or domain-specific expertise is required but not adequately \\nrepresented in their training data. For instance, when asked to p rovide highly \\nspecialized medical advice or legal analysis, the model may generate plausible -\\nsounding but incorrect or outdated information.  \\n \\n9. Attention mechanisms in Large Language Models enable the model to focus on the \\nmost relevant parts of the input text when processing a sequence, allowing it to \\nunderstand the context and relationships between words. By assigning different '),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='4 \\n \\nweights to each word in the prompt, attention mechanism identifies which elements \\nof the sequence are important for predicting the next word or interpreting meaning. \\n  \\n10. Training an LLM for sentiment analysis involves adapting the model using a \\nlabelled dataset where each te xt sample is annotated with its corresponding \\nsentiment (e.g., positive, negative, neutral). During fine-tuning, the model learns to \\nassociate linguistic features like word choices, tone, and context with these \\nsentiment labels by minimizing errors in its predictions through supervised learning. \\nFor instance, fine-tuning a general-purpose LLM on a dataset of tweets allows it to \\nclassify the sentiment of new tweets, such as determining whether a tweet like \"I \\nlove this new government!\" conveys positivity or a tweet like \"This app spreads \\nfake news” conveys negativity. \\n \\n11. The concept of Zero-shot learning revolves around the ability of a Large Language \\nModel to perform tasks it has not been explicitly trained on by leveraging its general \\nunderstanding of language and knowledge encoded during pre -training. This is \\nbecause it has been exposed to diverse and extensive data during training, allowing \\nit to recognize patterns, relationships, and instructions even for unfamiliar tasks.  \\n \\n12. Ethical concerns surrounding LLMs include biases, misinformation, and potential \\nmisuse. LLMs can reinforce biases embedded in their training data, leading to \\ndiscriminatory or unfair outputs, especially in sensitive applications like hiring or \\nlaw enforcement. Also, the misu se of LLMs for ulterior purposes like creating \\ndeceptive deepfakes, automating sp am, or spreading disinformation can put the \\nsociety at risks. If trained on the necessary data, in the future, multimodal systems \\nwill be able to think and act exactly like whoever they are modelled after, having \\nthe same physical, phonetical features. ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='2 \\n \\ni. Biases in Outputs: LLMs often represent biases embedded in the training data, \\nleading to the generation of outputs that reflect stereotypes, discriminatory \\npatterns, or harmful content. When the data upon which an LLM is trained is \\nimbalanced, and has some socio-cultural or socio-political patterns, it will be \\ninevitable for the models to reinforc e these imbalances. An example of this is \\nthe varying opinions and dispositions of people towards LGBTQ as its legality \\nis not universal and contradicts some religious doctrines. \\nii. High Computational Cost: Training and deploying LLMs require substantial \\ncomputational resources, including high -performance GPUs or TPUs and \\nsignificant amounts of electricity. \\niii. Data Privacy Concern: LLMs trained on large datase ts will inadvertently \\nrephrase and reproduce sensitive information which can put human lives at risk \\nand jeopardise security. \\niv. Hallucination and Misinformation: LLMs sometimes generate content that is \\nincorrect and sound fabricated. This can lead to misinformation, and reliance on \\nsuch information can wreak havoc. An example of this is medical content that \\nmay not be based on scientific authorization. Also, the misuse of LLMs can lead \\nto harmful applications such as generating deepfake  content, spreading \\ndisinformation, or automating harmful behaviour.  \\nv. Availablity: The large size and resource demand of LLMs make deployment on \\nedge devices challenging, limiting the accessibility by many users. \\n5. Fine-tuning: This is the process of adapting a pre-trained neural network which has \\nbeen trained on a huge data to now  perform a new, specific, or streamlined task. It \\nfocuses on performing a specialized task rather than a wide-scope task. \\nFine-tuning can be applied in various fields, for instance, it can help with customer \\nservice by enabling the LLMs model to understand and resolve customer queries, \\nand proffer solutions. It can also be used in creative writing by fine-tuning human-\\nwritten scripts to meet a specific standard or style of writing. \\n ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='1 \\n \\nLLM ASSIGNMENT SOLUTIONS \\n \\n1. LLMs is an alias for Large Language Models which are deep learning models that are \\nbased on neural networks with very huge parameters. These models learn from \\ntrillions of datasets to understand patterns in human languag es: the contexts,'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='grammar, semantics and every other elements of human languages. \\n \\n2. LLMs are based on what is called Transformer architecture, and this enables the \\nsequential procession of text efficiently by understanding the interrelatedness of'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='words in sent ences, paragraphs, and larger amounts of words. This  allows these \\nmodels to have the capability to perform many natural language processing such as \\nsummarisation and translation. \\nThey rely on transfer learning, this means that they can transfer whatever th ey have'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='learned during their training with a very huge dataset to slimmer and more focused \\ntext-related tasks. \\n \\n3. Customer service, content generation, and chatbots derive great benefits from Large \\nLanguage Models (LLMs) because they provide natural, context ual, and efficient'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='interactions. In customer service , for instance, they improve response speed and \\naccuracy, and they can proffer solutions without human engagement, and this can be \\ndone any time of the day. Also, in content generation, LLMs can create high-quality,'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 0, 'page_label': '1'}, page_content='creative, and coherent text, that will take a lot of hours for humans to generate. LLMs \\nalso improve chatbots by engaging in more human-like conversations, understanding \\ncomplex queries, and adapting to diverse contexts.  \\n \\n4. Common challenges include:'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='2 \\n \\ni. Biases in Outputs: LLMs often represent biases embedded in the training data, \\nleading to the generation of outputs that reflect stereotypes, discriminatory \\npatterns, or harmful content. When the data upon which an LLM is trained is'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='imbalanced, and has some socio-cultural or socio-political patterns, it will be \\ninevitable for the models to reinforc e these imbalances. An example of this is \\nthe varying opinions and dispositions of people towards LGBTQ as its legality'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='is not universal and contradicts some religious doctrines. \\nii. High Computational Cost: Training and deploying LLMs require substantial \\ncomputational resources, including high -performance GPUs or TPUs and \\nsignificant amounts of electricity.'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='significant amounts of electricity. \\niii. Data Privacy Concern: LLMs trained on large datase ts will inadvertently \\nrephrase and reproduce sensitive information which can put human lives at risk \\nand jeopardise security.'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='and jeopardise security. \\niv. Hallucination and Misinformation: LLMs sometimes generate content that is \\nincorrect and sound fabricated. This can lead to misinformation, and reliance on \\nsuch information can wreak havoc. An example of this is medical content that'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='may not be based on scientific authorization. Also, the misuse of LLMs can lead \\nto harmful applications such as generating deepfake  content, spreading \\ndisinformation, or automating harmful behaviour.  \\nv. Availablity: The large size and resource demand of LLMs make deployment on'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='edge devices challenging, limiting the accessibility by many users. \\n5. Fine-tuning: This is the process of adapting a pre-trained neural network which has \\nbeen trained on a huge data to now  perform a new, specific, or streamlined task. It'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='focuses on performing a specialized task rather than a wide-scope task. \\nFine-tuning can be applied in various fields, for instance, it can help with customer \\nservice by enabling the LLMs model to understand and resolve customer queries,'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 1, 'page_label': '2'}, page_content='and proffer solutions. It can also be used in creative writing by fine-tuning human-\\nwritten scripts to meet a specific standard or style of writing.'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='3 \\n \\n6. The training phase of an LLM involves teaching the model to understand language \\npatterns by processing huge datasets and adjusting internal paramete rs (weights) \\nthrough iterative forward and backward passes to minimize prediction errors. This'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='phase is resource-intensive, requiring significant computational power and time. On \\nthe other hand, the inference phase applies the already trained model to real -world \\ntasks by performing a single forward pass to generate outputs like text completions'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='or answers. Training occurs infrequently and focuses on learning, while inference \\nhappens repeatedly during application. \\n \\n7. Large Language Models manage long inputs or  multiple paragraphs of text by \\nbreaking them into smaller units, like words. Transformers then use mechanisms'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='like self-attention to understand relationships between these words, even when they \\nappear far apart in the sequence. This ensures LLMs maintain coherence while \\nhandling large inputs effectively. \\n \\n8. Large Language Models might perform badly in a situation where there is'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='ambiguous or poorly framed prompts, where the model might misinterpret user \\nintent or generate irrelevant or nonsensical outputs due to the lack of clear context. \\nAnother scenario where LLMs might perform poorly is in a situation whereby'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='precise factual accuracy or domain-specific expertise is required but not adequately \\nrepresented in their training data. For instance, when asked to p rovide highly \\nspecialized medical advice or legal analysis, the model may generate plausible -\\nsounding but incorrect or outdated information.'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 2, 'page_label': '3'}, page_content='sounding but incorrect or outdated information.  \\n \\n9. Attention mechanisms in Large Language Models enable the model to focus on the \\nmost relevant parts of the input text when processing a sequence, allowing it to \\nunderstand the context and relationships between words. By assigning different'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='4 \\n \\nweights to each word in the prompt, attention mechanism identifies which elements \\nof the sequence are important for predicting the next word or interpreting meaning. \\n  \\n10. Training an LLM for sentiment analysis involves adapting the model using a'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='labelled dataset where each te xt sample is annotated with its corresponding \\nsentiment (e.g., positive, negative, neutral). During fine-tuning, the model learns to \\nassociate linguistic features like word choices, tone, and context with these'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='sentiment labels by minimizing errors in its predictions through supervised learning. \\nFor instance, fine-tuning a general-purpose LLM on a dataset of tweets allows it to \\nclassify the sentiment of new tweets, such as determining whether a tweet like \"I'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='love this new government!\" conveys positivity or a tweet like \"This app spreads \\nfake news” conveys negativity. \\n \\n11. The concept of Zero-shot learning revolves around the ability of a Large Language \\nModel to perform tasks it has not been explicitly trained on by leveraging its general'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='understanding of language and knowledge encoded during pre -training. This is \\nbecause it has been exposed to diverse and extensive data during training, allowing \\nit to recognize patterns, relationships, and instructions even for unfamiliar tasks.'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='12. Ethical concerns surrounding LLMs include biases, misinformation, and potential \\nmisuse. LLMs can reinforce biases embedded in their training data, leading to \\ndiscriminatory or unfair outputs, especially in sensitive applications like hiring or'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='law enforcement. Also, the misu se of LLMs for ulterior purposes like creating \\ndeceptive deepfakes, automating sp am, or spreading disinformation can put the \\nsociety at risks. If trained on the necessary data, in the future, multimodal systems'),\n",
       " Document(metadata={'source': '../data/LLM_Answers.pdf', 'page': 3, 'page_label': '4'}, page_content='will be able to think and act exactly like whoever they are modelled after, having \\nthe same physical, phonetical features.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 \\n \\nLLM ASSIGNMENT SOLUTIONS \\n \\n1. LLMs is an alias for Large Language Models which are deep learning models that are \\nbased on neural networks with very huge parameters. These models learn from \\ntrillions of datasets to understand patterns in human languag es: the contexts,'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('1 \\n \\nLLM ASSIGNMENT SOLUTIONS \\n \\n1. LLMs is an alias for Large Language Models which are deep learning models that are \\nbased on neural networks with very huge parameters. These models learn from \\ntrillions of datasets to understand patterns in h uman languag es: the contexts,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/cover_letter.txt'}, page_content='Dear Sir or Madam,\\nI was immediately drawn to the ad in which you stated you are looking for a transcriptionist. The profile you have outlined fits me very well, I am a trained voice writer using the combination of Dragon and ExclipseVox software, speed of 200WPM at a minimum of 96% accuracy.  I have attached my resume. Thanks very much as I await a positive response.\\n\\nIsaiah Oluwatosin Ajayi.\\najacent4sure@gmail.com\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"../data/cover_letter.txt\")\n",
    "text_document = loader.load()\n",
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cover_letter.txt\")as file:\n",
    "    cover_letter = file.read()   ##THis is not needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Sir or Madam,\\nI was immediately drawn to the ad in which you stated you are looking for a transcriptionist. The profile you have outlined fits me very well, I am a trained voice writer using the combination of Dragon and ExclipseVox software, speed of 200WPM at a minimum of 96% accuracy.  I have attached my resume. Thanks very much as I await a positive response.\\n\\nIsaiah Oluwatosin Ajayi.\\najacent4sure@gmail.com\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_letter ##THis is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
    "final_doc = text_splitter.create_documents(cover_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='D'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='S'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='M'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content=','), Document(metadata={}, page_content='I'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='k'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='g'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='T'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content=','), Document(metadata={}, page_content='I'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='g'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='b'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='D'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='g'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='E'), Document(metadata={}, page_content='x'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='V'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='x'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content=','), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='2'), Document(metadata={}, page_content='0'), Document(metadata={}, page_content='0'), Document(metadata={}, page_content='W'), Document(metadata={}, page_content='P'), Document(metadata={}, page_content='M'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='f'), Document(metadata={}, page_content='9'), Document(metadata={}, page_content='6'), Document(metadata={}, page_content='%'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='I'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='d'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='T'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='k'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='I'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='v'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='p'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='I'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='h'), Document(metadata={}, page_content='O'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='w'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='A'), Document(metadata={}, page_content='j'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='y'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='j'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='n'), Document(metadata={}, page_content='t'), Document(metadata={}, page_content='4'), Document(metadata={}, page_content='s'), Document(metadata={}, page_content='u'), Document(metadata={}, page_content='r'), Document(metadata={}, page_content='e'), Document(metadata={}, page_content='@'), Document(metadata={}, page_content='g'), Document(metadata={}, page_content='m'), Document(metadata={}, page_content='a'), Document(metadata={}, page_content='i'), Document(metadata={}, page_content='l'), Document(metadata={}, page_content='.'), Document(metadata={}, page_content='c'), Document(metadata={}, page_content='o'), Document(metadata={}, page_content='m')]\n"
     ]
    }
   ],
   "source": [
    "print(final_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
